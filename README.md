# Cross Validation
## Using Boston Housing Data 

** Building upon validating "generalizeability" of models by testing them on unseen data through two methods : 
  - Train/Test Split
  - K-Fold Cross-Validation ** 



We prevent overfitting by not using all the data, and
We retain some remaining data to evaluate our model.
In the case of cross-validation, the model fitting and evaluation is performed multiple times on different train/test splits of the data.

Ultimately we can use the training/test validation framework to compare multiple models on the same dataset. This could be comparisons of two linear models, or of completely different models on the same data.

